{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib import style\n",
    "style.use(\"fivethirtyeight\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima=pd.read_csv(\"diabetes.csv\")\n",
    "pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar=StandardScaler()\n",
    "x=np.array(pima.drop(\"Outcome\",axis=1))\n",
    "#x=scalar.fit_transform(x)\n",
    "y=np.array(pima[\"Outcome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(x_train.shape[1],x_train.shape[0])\n",
    "x_test=x_test.reshape(x_test.shape[1],x_test.shape[0])\n",
    "y_train=y_train.reshape(1,y_train.shape[0])\n",
    "y_test=y_test.reshape(1,y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SANN:\n",
    "    \n",
    "    def __init__(self,shapes,layers,neurons,activation_function):\n",
    "        self.shapes=shapes\n",
    "        self.layers=layers\n",
    "        self.neurons=neurons\n",
    "        self.activation_function=activation_function\n",
    "        \n",
    "    def layersizes(self):\n",
    "        \n",
    "        self.sizes=[]\n",
    "        self.sizes.append(self.shapes[0])\n",
    "        for i in self.neurons:\n",
    "            self.sizes.append(i)\n",
    "        self.sizes.append(self.shapes[1])\n",
    "        \n",
    "        return self.sizes\n",
    "    \n",
    "    def initializing_parameters(self):\n",
    "        \n",
    "        layer_dims=self.layersizes()\n",
    "        self.parameters={}\n",
    "        l=len(layer_dims)-1\n",
    "        \n",
    "        for j in range(1,l):\n",
    "            self.parameters[\"W\"+str(j)]=np.random.randn(layer_dims[j],layer_dims[j-1])*0.01\n",
    "            self.parameters[\"b\"+str(j)]=np.zeros((layer_dims[j],1))\n",
    "        \n",
    "        return self.parameters\n",
    "    \n",
    "    def forward_propagation(self,X,parameters):\n",
    "        \n",
    "        cache={\"A0\":X}\n",
    "        \n",
    "        \n",
    "        for k in range(1,self.layers+1):\n",
    "            \n",
    "            cache[\"Z\"+str(k)]=np.dot(parameters[\"W\"+str(k)],cache[\"A\"+str(k-1)])+parameters[\"b\"+str(k)]\n",
    "            \n",
    "            if self.activation_function[k-1]==\"tanh\":\n",
    "                cache[\"A\"+str(k)]=np.tanh(cache[\"Z\"+str(k)])\n",
    "                \n",
    "            elif self.activation_function[k-1]==\"sigmoid\":\n",
    "                cache[\"A\"+str(k)]=1/(1+np.exp(-cache[\"Z\"+str(k)]))\n",
    "                \n",
    "            elif self.activation_function[k-1]==\"relu\":\n",
    "                cache[\"A\"+str(k)]=np.maximum(0,cache[\"Z\"+str(k)])\n",
    "                \n",
    "        return cache[\"A\"+str(self.layers)],cache\n",
    "            \n",
    "            \n",
    "    def compute_cost(self,Af,Y):\n",
    "        \n",
    "        m=Y.shape[1]\n",
    "\n",
    "        cost=-np.sum((np.dot(np.log(Af),Y.T)+np.dot(np.log(1-Af),(1-Y).T)))/m\n",
    "\n",
    "        cost=float(np.squeeze(cost))\n",
    "\n",
    "        return cost\n",
    "    \n",
    "    def backward_propagation(self,X,Y,cache,parameters):\n",
    "        \n",
    "        m=X.shape[1]\n",
    "        \n",
    "        active=self.activation_function[:-1]\n",
    "        derivatives={}\n",
    "        grads={}\n",
    "        \n",
    "        derivatives[\"dZ\"+str(self.layers)]=np.subtract(cache[\"A\"+str(self.layers)],Y)\n",
    "        grads[\"dW\"+str(self.layers)]=np.dot(derivatives[\"dZ\"+str(self.layers)],cache[\"A\"+str(self.layers-1)].T)\n",
    "        grads[\"db\"+str(self.layers)]=(np.sum(derivatives[\"dZ\"+str(self.layers)],axis=1,keepdims=True))/m\n",
    "        \n",
    "        for b in range(self.layers-1,0,-1):\n",
    "            if active[-1]==\"tanh\":\n",
    "                derivatives[\"dZ\"+str(b)]=np.dot(parameters[\"W\"+str(b+1)].T,derivatives[\"dZ\"+str(b+1)])*(1-np.power(cache[\"A\"+str(b)],2))\n",
    "                grads[\"dW\"+str(b)]=np.dot(derivatives[\"dZ\"+str(b)],cache[\"A\"+str(b-1)].T)/m\n",
    "                active.pop()\n",
    "            elif active[-1]==\"sigmoid\":\n",
    "                dr=1/(1+np.exp(-cache[\"A\"+str(b)]))\n",
    "                derivatives[\"dZ\"+str(b)]=np.dot(parameters[\"W\"+str(b+1)].T,derivatives[\"dZ\"+str(b+1)])*(dr*(1-dr))\n",
    "                grads[\"dW\"+str(b)]=np.dot(derivatives[\"dZ\"+str(b)],cache[\"A\"+str(b-1)].T)/m\n",
    "                active.pop()\n",
    "            elif active[-1]==\"relu\":\n",
    "                if (cache[\"A\"+str(b)]<0).any():\n",
    "                    t=0\n",
    "                else:\n",
    "                    t=1\n",
    "                derivatives[\"dZ\"+str(b)]=np.dot(parameters[\"W\"+str(b+1)].T,derivatives[\"dZ\"+str(b+1)])*t\n",
    "                grads[\"dW\"+str(b)]=np.dot(derivatives[\"dZ\"+str(b)],cache[\"A\"+str(b-1)].T)/m\n",
    "                active.pop()\n",
    "                \n",
    "            grads[\"db\"+str(b)]=(np.sum(derivatives[\"dZ\"+str(b)],axis=1,keepdims=True))/m\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    \n",
    "    def update_parameters(self,parameters,grads,lr):\n",
    "        \n",
    "        new_parameters={}\n",
    "        \n",
    "        for i in range(1,self.layers+1):\n",
    "            \n",
    "            new_parameters[\"W\"+str(i)]=parameters[\"W\"+str(i)]-lr*grads[\"dW\"+str(i)]\n",
    "            new_parameters[\"b\"+str(i)]=parameters[\"b\"+str(i)]-lr*grads[\"db\"+str(i)]\n",
    "            \n",
    "        return new_parameters\n",
    "     \n",
    "    def fit(self,training_set,validation_set,epochs,learning_rate,verbose=False):\n",
    "        \n",
    "        self.X=training_set[0]\n",
    "        self.Y=training_set[1]\n",
    "        self.cost_error=[]\n",
    "        self.accuracy_score=[]\n",
    "        self.weights=self.initializing_parameters()\n",
    "        \n",
    "        for j in range(epochs):\n",
    "            \n",
    "            Afinal,cache=self.forward_propagation(self.X,self.weights)\n",
    "            \n",
    "            cost=self.compute_cost(Afinal,self.Y)\n",
    "            \n",
    "            grads=self.backward_propagation(self.X,self.Y,cache,self.weights)\n",
    "            \n",
    "            self.weights=self.update_parameters(self.weights,grads,learning_rate)\n",
    "            \n",
    "            s=1000\n",
    "            if (j%s==0):\n",
    "                y_pred=self.predictions(self.X)\n",
    "                acc=accuracy_score(self.Y[0],y_pred)*100\n",
    "                self.cost_error.append(cost)\n",
    "                self.accuracy_score.append(acc)\n",
    "                print(f\"cost at {j} iteration is ====> {cost} and accuracy score is {acc}\")\n",
    "    \n",
    "        return self.cost_error,self.accuracy_score\n",
    "    \n",
    "    def predictions(self,X):\n",
    "            Afinal,cache=self.forward_propagation(X,self.weights)\n",
    "            predictions = []\n",
    "            for i in range(len(Afinal[0])):\n",
    "                if (Afinal[0][i]>0.5).any():\n",
    "                    predictions.append(1)\n",
    "                else:\n",
    "                    predictions.append(0)\n",
    "            predictions=np.array(predictions)\n",
    "            return predictions\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost at 0 iteration is ====> 0.6931491791617985 and accuracy score is 64.40972222222221\n",
      "cost at 1000 iteration is ====> 0.6509979220630847 and accuracy score is 64.40972222222221\n",
      "cost at 2000 iteration is ====> 0.6509667638775476 and accuracy score is 64.40972222222221\n",
      "cost at 3000 iteration is ====> 0.6509182348144056 and accuracy score is 64.40972222222221\n",
      "cost at 4000 iteration is ====> 0.6508251957948235 and accuracy score is 64.40972222222221\n",
      "cost at 5000 iteration is ====> 0.6506058587911134 and accuracy score is 64.40972222222221\n",
      "cost at 6000 iteration is ====> 0.6498942774772958 and accuracy score is 64.40972222222221\n",
      "cost at 7000 iteration is ====> 0.6449215067500172 and accuracy score is 64.40972222222221\n",
      "cost at 8000 iteration is ====> 0.5710040477215946 and accuracy score is 72.04861111111111\n",
      "cost at 9000 iteration is ====> 0.4888972683640264 and accuracy score is 77.60416666666666\n",
      "cost at 10000 iteration is ====> 0.42555995496659055 and accuracy score is 80.90277777777779\n",
      "cost at 11000 iteration is ====> 0.37942163081714325 and accuracy score is 82.98611111111111\n",
      "cost at 12000 iteration is ====> 0.29912630415422675 and accuracy score is 87.15277777777779\n",
      "cost at 13000 iteration is ====> 0.24231822554661042 and accuracy score is 89.75694444444444\n",
      "cost at 14000 iteration is ====> 0.2757216293514936 and accuracy score is 88.02083333333334\n",
      "cost at 15000 iteration is ====> 0.3035047305927703 and accuracy score is 86.11111111111111\n",
      "cost at 16000 iteration is ====> 1.2054430917827017 and accuracy score is 80.55555555555556\n",
      "cost at 17000 iteration is ====> 0.12134533911834408 and accuracy score is 95.13888888888889\n",
      "cost at 18000 iteration is ====> 0.6688388929404538 and accuracy score is 73.26388888888889\n",
      "cost at 19000 iteration is ====> 0.09434801284876393 and accuracy score is 95.83333333333334\n"
     ]
    }
   ],
   "source": [
    "shapes=[x_train.shape[0],y_train.shape[0]]\n",
    "sample=SANN(shapes,5,[128,64,32,16,1],[\"tanh\",\"tanh\",\"tanh\",\"tanh\",\"sigmoid\"])\n",
    "loss,accuracy=sample.fit(training_set=[x_train,y_train],\n",
    "             validation_set=[x_test,y_test],\n",
    "             epochs=20000,learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "%matplotlib qt\n",
    "for i in range(1,len(loss)):\n",
    "    x=range(0,i)\n",
    "    y=loss[0:i]\n",
    "    plt.plot(x,y)\n",
    "    plt.ylabel(\"cost function error\")\n",
    "    plt.xlabel(\"cost function for every 1000 iterations\")\n",
    "    plt.title(str(i))\n",
    "    plt.draw()\n",
    "    plt.pause(0.1)\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "%matplotlib qt\n",
    "for i in range(1,len(accuracy)):\n",
    "    x=range(0,i)\n",
    "    y=accuracy[0:i]\n",
    "    plt.plot(x,y)\n",
    "    plt.ylabel(\"training accuracy\")\n",
    "    plt.xlabel(\"training accuracy 1000 iterations\")\n",
    "    plt.title(str(i))\n",
    "    plt.draw()\n",
    "    plt.pause(0.1)\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[80 49]\n",
      " [39 24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.65       129\n",
      "           1       0.33      0.38      0.35        63\n",
      "\n",
      "    accuracy                           0.54       192\n",
      "   macro avg       0.50      0.50      0.50       192\n",
      "weighted avg       0.56      0.54      0.55       192\n",
      "\n",
      "0.5416666666666666\n"
     ]
    }
   ],
   "source": [
    "y_pred=sample.predictions(x_test)\n",
    "print(confusion_matrix(y_test[0],y_pred))\n",
    "print(classification_report(y_test[0],y_pred))\n",
    "print(accuracy_score(y_test[0],y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
